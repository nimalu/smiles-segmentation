/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/model_zoo/model_zoo.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
âœ“ Registered SMILES dataset splits:
  Train: 8000 images (80%)
  Val: 2000 images (20%)
  Categories: ['AROMATIC-NONE', 'ATOM', 'DOUBLE-NONE', 'SINGLE-BEGINDASH', 'SINGLE-BEGINWEDGE', 'SINGLE-NONE']
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_SQRT: True
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('smiles_val',)
  TRAIN: ('smiles_train',)
FLOAT32_PRECISION: 
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: False
  CROP:
    ENABLED: True
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE: [0.8, 1.0]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: bitmask
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1400
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (960, 1024, 1100)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  IMPLICIT_POINTREND:
    IMAGE_FEATURE_ENABLED: True
    PARAMS_L2_REGULARIZER: 1e-05
    POS_ENC_ENABLED: True
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  POINT_HEAD:
    CLS_AGNOSTIC_MASK: False
    COARSE_PRED_EACH_LAYER: True
    COARSE_SEM_SEG_HEAD_NAME: SemSegFPNHead
    FC_DIM: 256
    IMPORTANCE_SAMPLE_RATIO: 0.75
    IN_FEATURES: ('p2',)
    IN_TEST: True
    NAME: StandardPointHead
    NUM_CLASSES: 6
    NUM_FC: 3
    OVERSAMPLE_RATIO: 3
    SUBDIVISION_NUM_POINTS: 8192
    SUBDIVISION_STEPS: 5
    TRAIN_NUM_POINTS: 2048
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: True
    USE_FED_LOSS: False
    USE_SIGMOID_CE: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 6
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    FC_DIM: 1024
    IN_FEATURES: ('p2',)
    NAME: PointRendMaskHead
    NORM: 
    NUM_CONV: 4
    NUM_FC: 2
    OUTPUT_SIDE_RESOLUTION: 7
    POINT_HEAD_ON: True
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: 
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    CONV_DIMS: [-1]
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: detectron2://PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_edd263.pkl
OUTPUT_DIR: output/20260114_161505
SEED: -1
SOLVER:
  AMP:
    ENABLED: True
  BASE_LR: 0.002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 250
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 8
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2000
  MOMENTUM: 0.9
  NESTEROV: False
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: False
  STEPS: (1000, 1800)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 250
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: None
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 100
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[01/14 16:15:07 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=7, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=24, bias=True)
    )
    (mask_head): PointRendMaskHead(
      (point_head): StandardPointHead(
        (fc1): Conv1d(262, 256, kernel_size=(1,), stride=(1,))
        (fc2): Conv1d(262, 256, kernel_size=(1,), stride=(1,))
        (fc3): Conv1d(262, 256, kernel_size=(1,), stride=(1,))
        (predictor): Conv1d(262, 6, kernel_size=(1,), stride=(1,))
      )
      (coarse_head): ConvFCHead(
        (reduce_spatial_dim_conv): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=1024, bias=True)
        (prediction): Linear(in_features=1024, out_features=294, bias=True)
      )
    )
  )
)
[01/14 16:15:07 d2.data.build]: Removed 0 images with no usable annotations. 8000 images left.
[01/14 16:15:07 d2.data.build]: Distribution of instances among all 6 categories:
|   category    | #instances   |   category    | #instances   |  category   | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-----------:|:-------------|
| AROMATIC-NONE | 20393        |     ATOM      | 18777        | DOUBLE-NONE | 5083         |
| SINGLE-BEGI.. | 2319         | SINGLE-BEGI.. | 3946         | SINGLE-NONE | 32706        |
|               |              |               |              |             |              |
|     total     | 83224        |               |              |             |              |
[01/14 16:15:07 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.8, 1.0]), ResizeShortestEdge(short_edge_length=(960, 1024, 1100), max_size=1400, sample_style='choice'), RandomFlip()]
[01/14 16:15:07 d2.data.build]: Using training sampler TrainingSampler
[01/14 16:15:07 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/14 16:15:07 d2.data.common]: Serializing 8000 elements to byte tensors and concatenating them all ...
[01/14 16:15:07 d2.data.common]: Serialized dataset takes 49.20 MiB
[01/14 16:15:07 d2.data.build]: Making batched data loader with batch_size=8
/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/engine/train_loop.py:474: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  grad_scaler = GradScaler()
[01/14 16:15:07 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from detectron2://PointRend/InstanceSegmentation/pointrend_rcnn_R_50_FPN_3x_coco/164955410/model_final_edd263.pkl ...
WARNING [01/14 16:15:08 d2.projects.point_rend.mask_head]: Weight format of PointRend models have changed! Applying automatic conversion now ...
Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (7, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (7,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (24, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (24,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.coarse_head.prediction.weight' to the model due to incompatible shapes: (3920, 1024) in the checkpoint but (294, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.coarse_head.prediction.bias' to the model due to incompatible shapes: (3920,) in the checkpoint but (294,) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.point_head.fc1.weight' to the model due to incompatible shapes: (256, 336, 1) in the checkpoint but (256, 262, 1) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.point_head.fc2.weight' to the model due to incompatible shapes: (256, 336, 1) in the checkpoint but (256, 262, 1) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.point_head.fc3.weight' to the model due to incompatible shapes: (256, 336, 1) in the checkpoint but (256, 262, 1) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.point_head.predictor.weight' to the model due to incompatible shapes: (80, 336, 1) in the checkpoint but (6, 262, 1) in the model! You might want to double check if this is expected.
Skip loading parameter 'roi_heads.mask_head.point_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
roi_heads.mask_head.coarse_head.prediction.{bias, weight}
roi_heads.mask_head.point_head.fc1.weight
roi_heads.mask_head.point_head.fc2.weight
roi_heads.mask_head.point_head.fc3.weight
roi_heads.mask_head.point_head.predictor.{bias, weight}
[01/14 16:15:08 d2.engine.train_loop]: Starting training from iteration 0
[01/14 16:15:08 d2.data.build]: Distribution of instances among all 6 categories:
|   category    | #instances   |   category    | #instances   |  category   | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-----------:|:-------------|
| AROMATIC-NONE | 5123         |     ATOM      | 4637         | DOUBLE-NONE | 1255         |
| SINGLE-BEGI.. | 552          | SINGLE-BEGI.. | 943          | SINGLE-NONE | 8169         |
|               |              |               |              |             |              |
|     total     | 20679        |               |              |             |              |
[01/14 16:15:08 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[01/14 16:15:08 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/14 16:15:08 d2.data.common]: Serializing 2000 elements to byte tensors and concatenating them all ...
[01/14 16:15:08 d2.data.common]: Serialized dataset takes 12.18 MiB
/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
W0114 16:15:15.121000 803331 .venv/lib/python3.12/site-packages/torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.
/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/optim/lr_scheduler.py:192: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
[01/14 16:15:39 d2.utils.events]:  eta: 0:35:21  iter: 19  total_loss: 5.618  loss_cls: 1.757  loss_box_reg: 0.8769  loss_mask: 0.6862  loss_mask_point: 0.5086  loss_rpn_cls: 1.362  loss_rpn_loc: 0.2315    time: 1.0535  last_time: 0.3901  data_time: 0.1282  last_data_time: 0.0180   lr: 0.00015385  max_mem: 11476M
[01/14 16:16:02 d2.utils.events]:  eta: 0:39:47  iter: 39  total_loss: 2.549  loss_cls: 0.7999  loss_box_reg: 0.8902  loss_mask: 0.4477  loss_mask_point: 0.3071  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.127    time: 1.0764  last_time: 1.2198  data_time: 0.1215  last_data_time: 0.0201   lr: 0.00031369  max_mem: 12109M
[01/14 16:16:21 d2.utils.events]:  eta: 0:39:08  iter: 59  total_loss: 2.139  loss_cls: 0.5901  loss_box_reg: 0.8356  loss_mask: 0.2785  loss_mask_point: 0.2489  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.115    time: 1.0251  last_time: 1.5177  data_time: 0.1007  last_data_time: 0.0214   lr: 0.00047353  max_mem: 12512M
[01/14 16:16:35 d2.utils.events]:  eta: 0:21:49  iter: 79  total_loss: 1.621  loss_cls: 0.4151  loss_box_reg: 0.7082  loss_mask: 0.1946  loss_mask_point: 0.1818  loss_rpn_cls: 0.009784  loss_rpn_loc: 0.09676    time: 0.9516  last_time: 0.4785  data_time: 0.1061  last_data_time: 0.1204   lr: 0.00063337  max_mem: 12512M
[01/14 16:16:52 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[01/14 16:16:52 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[01/14 16:16:52 d2.data.common]: Serializing 2000 elements to byte tensors and concatenating them all ...
[01/14 16:16:52 d2.data.common]: Serialized dataset takes 12.18 MiB
WARNING [01/14 16:16:52 d2.engine.defaults]: No evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.
ERROR [01/14 16:16:52 d2.engine.train_loop]: Exception during training:
Traceback (most recent call last):
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/02_train.py", line 119, in after_step
    val_loss = self._compute_val_loss()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/02_train.py", line 159, in _compute_val_loss
    loss_dict = self.trainer.model(data)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 161, in forward
    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/modeling/proposal_generator/rpn.py", line 470, in forward
    assert gt_instances is not None, "RPN requires gt_instances in training!"
AssertionError: RPN requires gt_instances in training!
[01/14 16:16:52 d2.engine.hooks]: Overall training speed: 97 iterations in 0:01:30 (0.9314 s / it)
[01/14 16:16:52 d2.engine.hooks]: Total training time: 0:01:31 (0:00:01 on hooks)
[01/14 16:16:52 d2.utils.events]:  eta: 0:20:38  iter: 99  total_loss: 1.245  loss_cls: 0.3264  loss_box_reg: 0.4068  loss_mask: 0.1818  loss_mask_point: 0.1807  loss_rpn_cls: 0.008383  loss_rpn_loc: 0.1092    time: 0.9219  last_time: 0.6014  data_time: 0.1082  last_data_time: 0.2213   lr: 0.00079321  max_mem: 12512M
Traceback (most recent call last):
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/02_train.py", line 196, in <module>
    trainer.train()
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/02_train.py", line 185, in train
    super().train()
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/engine/defaults.py", line 520, in train
    super().train(self.start_iter, self.max_iter)
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/02_train.py", line 119, in after_step
    val_loss = self._compute_val_loss()
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/02_train.py", line 159, in _compute_val_loss
    loss_dict = self.trainer.model(data)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/modeling/meta_arch/rcnn.py", line 161, in forward
    proposals, proposal_losses = self.proposal_generator(images, features, gt_instances)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/pfs/data6/home/ka/ka_scc/ka_zr1174/smiles-segmentation/.venv/lib64/python3.12/site-packages/detectron2/modeling/proposal_generator/rpn.py", line 470, in forward
    assert gt_instances is not None, "RPN requires gt_instances in training!"
AssertionError: RPN requires gt_instances in training!

============================= JOB FEEDBACK =============================

NodeName=uc2n576
Job ID: 2924845
Cluster: uc3
User/Group: ka_zr1174/ka_scc
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 24
CPU Utilized: 00:03:13
CPU Efficiency: 3.87% of 01:23:12 core-walltime
Job Wall-clock time: 00:03:28
Memory Utilized: 3.33 GB
Memory Efficiency: 10.42% of 32.00 GB (32.00 GB/node)
